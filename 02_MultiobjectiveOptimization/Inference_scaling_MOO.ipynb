{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437ec025",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbcadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy matplotlib ipywidgets scipy pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d897a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded. Models: ['gpt5', 'gpt5-mini', 'gpt5-nano', 'nvidia-nemotron-ultra-253b', 'nvidia-nemotron-h-47b', 'nvidia-nemotron-nano-9b-v2', 'qwen3-max', 'qwen3-next-80b-a3b', 'qwen3-30b-a3b']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')  # Add parent directory for config access\n",
    "\n",
    "try:\n",
    "    from inference_scaling import *\n",
    "    \n",
    "    # Quick config check\n",
    "    import yaml\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Build path relative to this notebook file, not the current working directory\n",
    "    notebook_dir = Path(os.path.dirname(os.path.abspath('__file__')))\n",
    "    config_path = notebook_dir.parent / \"config.yaml\"\n",
    "\n",
    "    if not config_path.is_file():\n",
    "        raise FileNotFoundError(f\"Config file not found at expected path: {config_path}\")\n",
    "\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_data = yaml.safe_load(f)\n",
    "    print(\"Config loaded. Models:\", list(config_data['models'].keys()))\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Config error: {e}\")\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# # Add the current directory to Python path\n",
    "# sys.path.insert(0, os.path.dirname(os.path.abspath('__file__')))\n",
    "# sys.path.append('.')\n",
    "# sys.path.append(os.getcwd())\n",
    "\n",
    "# try:\n",
    "#     from inference_scaling import *\n",
    "# except ImportError as e:\n",
    "#     print(f\"Import error: {e}\")\n",
    "#     print(\"Current working directory:\", os.getcwd())\n",
    "#     print(\"Python path:\", sys.path)\n",
    "#     print(\"Files in current directory:\", os.listdir('.'))\n",
    "    \n",
    "# # import sys\n",
    "# # sys.path.append('.')\n",
    "# # from inference_scaling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20338837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Scaling Optimization — Monte Carlo Simulations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c828af4b42b434a85cb3247d645a0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model', options=('gpt5', 'gpt5-mini', 'gpt5-nano', 'nvidia-nemotro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function inference_scaling.update_visuals_mc(selected_model, C_max_total, T_max_total, acc_min, k_max=200, mc_trials=300, parallel_factor=None, seed=42)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# ===============================\n",
    "# INTERACTIVE WIDGET SETUP\n",
    "# ===============================\n",
    "C_max_total_default = 0.50   # Total budget $\n",
    "T_max_total_default = 60.0   # Total time budget seconds\n",
    "\n",
    "print(\"Inference Scaling Optimization — Monte Carlo Simulations\")\n",
    "\n",
    "widgets.interact(\n",
    "    update_visuals_mc,\n",
    "    selected_model=widgets.Dropdown(options=list(MODEL_CONFIGS.keys()),\n",
    "                                    value='gpt5', description='Model'),\n",
    "    C_max_total=widgets.FloatSlider(min=0.01, max=1.0, step=0.01,\n",
    "                              value=C_max_total_default, description=\"Max Total Cost ($)\"),\n",
    "    T_max_total=widgets.FloatSlider(min=60.0, max=60*60, step=1.0,\n",
    "                              value=T_max_total_default, description=\"Max Total Time (s)\"),\n",
    "    acc_min=widgets.FloatSlider(min=0.88, max=0.99, step=0.01,\n",
    "                                value=0.88, description=\"Min ACC\"),\n",
    "    k_max=widgets.IntSlider(min=0, max=2**7, step=4, value=128, description=\"k_max\"),\n",
    "    mc_trials=widgets.IntSlider(min=300, max=500, step=10, value=300, description=\"MC Trials\"),\n",
    "    parallel_factor=widgets.IntSlider(min=0, max=2**7, step=4,\n",
    "                                      value=MODEL_CONFIGS['gpt5'].default_parallel,\n",
    "                                      description=\"Parallelism (P)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3df67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbd017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference-optimization-moo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
