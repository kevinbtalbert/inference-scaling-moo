entries:
  - title: AI Inference Scaling Optimization
    label: inference-scaling-moo
    short_description: |
      Multi-objective optimization framework for efficient AI inference scaling to balance accuracy, cost, and latency.
    long_description: |
      This AMP introduces a framework for optimizing inference scaling through multi-objective optimization (MOO) using an interactive simulator.
      The repository includes a simulator that gets optimal scales for the inference, and it does not need any LLM operation.
      It models and balances trade-offs between accuracy, cost, and latency across multiple sample LLM configurations using Monte Carlo simulation. 
      The AMP helps researchers and engineers identify optimal inference scale, visualize feasible 3D trade-off spaces, and adapt scaling dynamically to environment constraints.
      
      ---------------------------
      IMPORTANT: Please read the following before proceeding. 
      This AMP includes or otherwise depends on certain third-party software packages. 
      Information about such third-party software packages are made available in the notice file associated with this AMP. 
      By configuring and launching this AMP, you will cause such third-party software packages to be downloaded and installed 
      into your environment, in some instances, from third partiesâ€™ websites. 
      For each third-party software package, please see the notice file and the applicable websites for more information, 
      including the applicable license terms. 
      If you do not wish to download and install the third-party software packages, 
      do not configure, launch, or otherwise use this AMP. 
      By configuring, launching, or otherwise using the AMP, you acknowledge the foregoing statement and 
      agree that Cloudera is not responsible or liable in any way for the third-party software packages.
    image_path: "https://github.com/user-attachments/assets/b9178ff5-98e2-4327-a0f8-7cfbdb190ebf"
    tags:
      - Multi-objective Optimization
      - Inference Scaling
      - Monte Carlo Simulation
      - LLM Efficiency
    git_url: "https://github.com/masonjung/inference-scaling-moo.git"
    git_ref: "main"
    is_prototype: true
    is_community: true
    is_new: true
