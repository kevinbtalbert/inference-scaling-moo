{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bdd2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b707b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# MODEL CONFIGURATION SYSTEM\n",
    "# ===============================\n",
    "\n",
    "# adjust the model inputs for the stochastic simulation based on your needs\n",
    "# assumeed parallelism is 8 by default\n",
    "# costs are in $ per million tokens\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for a specific model with its unique parameters.\"\"\"\n",
    "    def __init__(self, name, c_in, c_out, t_in, t_out,\n",
    "                 mu_Lin, sigma_Lin, mu_Lout, sigma_Lout,\n",
    "                 acc_mean, acc_std, default_parallel=8):\n",
    "        self.name = name\n",
    "        self.c_in = c_in      # $ per input token\n",
    "        self.c_out = c_out    # $ per output token\n",
    "        self.t_in = t_in      # sec per input token\n",
    "        self.t_out = t_out    # sec per output token\n",
    "        self.mu_Lin = mu_Lin\n",
    "        self.sigma_Lin = sigma_Lin\n",
    "        self.mu_Lout = mu_Lout\n",
    "        self.sigma_Lout = sigma_Lout\n",
    "        self.acc_mean = acc_mean\n",
    "        self.acc_std = acc_std\n",
    "        self.default_parallel = default_parallel\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"{self.name}: \"\n",
    "                f\"Cost(${self.c_in*1e6:.2f}/${self.c_out*1e6:.2f}/M), \"\n",
    "                f\"ACC({self.acc_mean:.3f}Â±{self.acc_std:.3f}), \"\n",
    "                f\"P={self.default_parallel}\")\n",
    "\n",
    "# Predefined models (params chosen to make kâ‰ˆ10â€“20 optimal under defaults)\n",
    "MODEL_CONFIGS = {\n",
    "    \"gpt5\": ModelConfig(\n",
    "        name=\"GPT-5\",\n",
    "        c_in=1.25 / 1_000_000,\n",
    "        c_out=10.00 / 1_000_000,\n",
    "        t_in=0.0005,     # â‰ˆ200 tok/s in\n",
    "        t_out=0.005,     # â‰ˆ200 tok/s out\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.85, acc_std=0.08,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"gpt5-mini\": ModelConfig(\n",
    "        name=\"GPT-5 Mini\",\n",
    "        c_in=0.25 / 1_000_000,\n",
    "        c_out=2.00 / 1_000_000,\n",
    "        t_in=0.00025, t_out=0.002,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.83, acc_std=0.09,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"gpt5-nano\": ModelConfig(\n",
    "        name=\"GPT-5 Nano\",\n",
    "        c_in=0.05 / 1_000_000,\n",
    "        c_out=0.40 / 1_000_000,\n",
    "        t_in=0.00010, t_out=0.0010,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.80, acc_std=0.10,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"nvidia-nemotron-ultra-253b\": ModelConfig(\n",
    "        name=\"Nvidia Llama Nemotron Ultra 253B\",\n",
    "        c_in=0.90 / 1_000_000,\n",
    "        c_out=2.80 / 1_000_000,\n",
    "        t_in=0.0010, t_out=0.0100,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.84, acc_std=0.02,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"nvidia-nemotron-h-47b\": ModelConfig(\n",
    "        name=\"Nvidia Nemotron H 47B\",\n",
    "        c_in=0.40 / 1_000_000,\n",
    "        c_out=1.50 / 1_000_000,\n",
    "        t_in=0.0004, t_out=0.0040,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.81, acc_std=0.025,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"nvidia-nemotron-nano-9b-v2\": ModelConfig(\n",
    "        name=\"Nvidia Nemotron Nano 9B v2\",\n",
    "        c_in=0.20 / 1_000_000,\n",
    "        c_out=1.00 / 1_000_000,\n",
    "        t_in=0.00012, t_out=0.0012,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.79, acc_std=0.03,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"qwen3-max\": ModelConfig(\n",
    "        name=\"Qwen3-Max\",\n",
    "        c_in=0.90 / 1_000_000,\n",
    "        c_out=2.40 / 1_000_000,\n",
    "        t_in=0.0008, t_out=0.0080,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.835, acc_std=0.042,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"qwen3-next-80b-a3b\": ModelConfig(\n",
    "        name=\"Qwen3-Next-80B-A3B\",\n",
    "        c_in=0.50 / 1_000_000,\n",
    "        c_out=1.25 / 1_000_000,\n",
    "        t_in=0.0004, t_out=0.0040,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.805, acc_std=0.058,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "    \"qwen3-30b-a3b\": ModelConfig(\n",
    "        name=\"Qwen3-30B-A3B\",\n",
    "        c_in=0.35 / 1_000_000,\n",
    "        c_out=0.90 / 1_000_000,\n",
    "        t_in=0.00025, t_out=0.0020,\n",
    "        mu_Lin=1500, sigma_Lin=120,\n",
    "        mu_Lout=3000, sigma_Lout=250,\n",
    "        acc_mean=0.785, acc_std=0.08,\n",
    "        default_parallel=8\n",
    "    ),\n",
    "}\n",
    "\n",
    "# sample cost and latency constraints\n",
    "C_max_default = 0.50   # $\n",
    "T_max_default = 60.0   # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6044c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# MONTE CARLO SIMULATION WITH AVERAGING\n",
    "# ===============================\n",
    "\n",
    "def simulate_mc_with_model(k, model_config, mc_trials=1000, parallel_factor=8, seed=42):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation: run mc_trials independent trials and return statistics.\n",
    "    This provides robust estimates with confidence intervals.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    costs, times, accs = [], [], []\n",
    "    \n",
    "    for trial in range(mc_trials):\n",
    "        # Draw per-inference lengths for this trial\n",
    "        Lin = rng.normal(model_config.mu_Lin, model_config.sigma_Lin, size=k)\n",
    "        Lin = np.clip(Lin, 1, 16 * model_config.mu_Lin)\n",
    "        Lout = rng.normal(model_config.mu_Lout, model_config.sigma_Lout, size=k)\n",
    "        Lout = np.clip(Lout, 1, 16 * Lin)\n",
    "\n",
    "        # Per-inference cost and time\n",
    "        trial_costs = model_config.c_in * Lin + model_config.c_out * Lout\n",
    "        trial_times = model_config.t_in * Lin + model_config.t_out * Lout\n",
    "\n",
    "        # Total cost for this trial\n",
    "        total_cost = trial_costs.sum()\n",
    "\n",
    "        # Parallel-adjusted time for this trial\n",
    "        if parallel_factor > 1:\n",
    "            batch_count = int(np.ceil(k / parallel_factor))\n",
    "            mean_time = float(np.mean(trial_times))\n",
    "            total_time = batch_count * mean_time\n",
    "        else:\n",
    "            total_time = float(np.sum(trial_times))\n",
    "\n",
    "        # Best-of-k accuracy for this trial\n",
    "        trial_accs = rng.normal(model_config.acc_mean, model_config.acc_std, size=k)\n",
    "        trial_accs = np.clip(trial_accs, 0.0, 1.0)\n",
    "        best_acc = float(np.max(trial_accs))\n",
    "\n",
    "        costs.append(total_cost)\n",
    "        times.append(total_time)\n",
    "        accs.append(best_acc)\n",
    "\n",
    "    # Convert to numpy arrays for statistics\n",
    "    costs = np.array(costs)\n",
    "    times = np.array(times)\n",
    "    accs = np.array(accs)\n",
    "\n",
    "    # Calculate statistics with confidence intervals\n",
    "    def calc_stats(data):\n",
    "        return {\n",
    "            \"mean\": float(np.mean(data)),\n",
    "            \"std\": float(np.std(data)),\n",
    "            \"ci95\": (float(np.percentile(data, 2.5)), float(np.percentile(data, 97.5)))\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"cost\": calc_stats(costs),\n",
    "        \"time\": calc_stats(times),\n",
    "        \"acc\": calc_stats(accs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2c48cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# UPDATED CONSTRAINT LOGIC - PER INFERENCE BASIS\n",
    "# ===============================\n",
    "\n",
    "def find_feasible_k_mc(model_config, C_max_per_inference, T_max_per_inference, k_max=200, mc_trials=500, parallel_factor=8, seed=42):\n",
    "    \"\"\"Find feasible k values using per-inference constraints.\"\"\"\n",
    "    feasible = []\n",
    "    print(f\"Computing feasible region with per-inference constraints...\")\n",
    "    print(f\"  C_max per inference: ${C_max_per_inference:.4f}\")\n",
    "    print(f\"  T_max per inference: {T_max_per_inference:.3f}s\")\n",
    "    \n",
    "    for k in range(1, k_max + 1):\n",
    "        if k % 20 == 0:\n",
    "            print(f\"  k={k}/{k_max}\")\n",
    "            \n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials, parallel_factor, seed + k)\n",
    "        \n",
    "        # Calculate per-inference costs and times\n",
    "        cost_per_inference = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inference = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        \n",
    "        # Use per-inference values for feasibility check\n",
    "        if cost_per_inference <= C_max_per_inference and time_per_inference <= T_max_per_inference:\n",
    "            feasible.append((k, stats))\n",
    "    \n",
    "    return feasible\n",
    "\n",
    "\n",
    "def find_accuracy_optimal_mc(model_config, C_max_per_inference, T_max_per_inference, acc_min=0.0, k_max=200, \n",
    "                            mc_trials=500, parallel_factor=8, seed=42):\n",
    "    \"\"\"Find accuracy-optimal k using per-inference constraints.\"\"\"\n",
    "    print(f\"Finding accuracy-optimal solution with per-inference constraints...\")\n",
    "    print(f\"  C_max per inference: ${C_max_per_inference:.4f}\")\n",
    "    print(f\"  T_max per inference: {T_max_per_inference:.3f}s\")\n",
    "    \n",
    "    best = None\n",
    "    best_acc = -1\n",
    "    \n",
    "    for k in range(1, k_max + 1):\n",
    "        if k % 20 == 0:\n",
    "            print(f\"  k={k}/{k_max}\")\n",
    "            \n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials, parallel_factor, seed + k)\n",
    "        \n",
    "        # Calculate per-inference costs and times\n",
    "        cost_per_inference = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inference = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        \n",
    "        # Check per-inference constraints\n",
    "        if (cost_per_inference <= C_max_per_inference and \n",
    "            time_per_inference <= T_max_per_inference and \n",
    "            stats[\"acc\"][\"mean\"] >= acc_min):\n",
    "            \n",
    "            if stats[\"acc\"][\"mean\"] > best_acc:\n",
    "                best_acc = stats[\"acc\"][\"mean\"]\n",
    "                best = {\n",
    "                    \"k\": k,\n",
    "                    \"total_cost\": stats[\"cost\"][\"mean\"],\n",
    "                    \"total_time\": stats[\"time\"][\"mean\"],\n",
    "                    \"cost_per_inference\": cost_per_inference,\n",
    "                    \"time_per_inference\": time_per_inference,\n",
    "                    \"accuracy\": stats[\"acc\"][\"mean\"],\n",
    "                    \"stats\": stats,\n",
    "                    \"model\": model_config.name\n",
    "                }\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def find_maximum_cube_solution_mc(model_config, C_max_per_inference, T_max_per_inference, acc_min=0.0, k_max=200,\n",
    "                                 mc_trials=500, parallel_factor=8, seed=42):\n",
    "    \"\"\"Find cube-optimal solution using per-inference constraints.\"\"\"\n",
    "    print(f\"Finding cube-optimal solution with per-inference constraints...\")\n",
    "    \n",
    "    best = None\n",
    "    best_vol = -1\n",
    "    \n",
    "    for k in range(1, k_max + 1):\n",
    "        if k % 20 == 0:\n",
    "            print(f\"  k={k}/{k_max}\")\n",
    "            \n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials, parallel_factor, seed + k)\n",
    "        \n",
    "        # Calculate per-inference metrics\n",
    "        cost_per_inference = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inference = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        acc_mean = stats[\"acc\"][\"mean\"]\n",
    "        \n",
    "        # Check per-inference constraints\n",
    "        if (cost_per_inference <= C_max_per_inference and \n",
    "            time_per_inference <= T_max_per_inference and \n",
    "            acc_mean >= acc_min):\n",
    "            \n",
    "            # Cube volume based on per-inference goodness\n",
    "            gC = max(0.0, 1.0 - cost_per_inference / C_max_per_inference)\n",
    "            gT = max(0.0, 1.0 - time_per_inference / T_max_per_inference)\n",
    "            gA = acc_mean\n",
    "            vol = gC * gT * gA\n",
    "            \n",
    "            if vol > best_vol:\n",
    "                best_vol = vol\n",
    "                best = {\n",
    "                    \"k\": k,\n",
    "                    \"total_cost\": stats[\"cost\"][\"mean\"],\n",
    "                    \"total_time\": stats[\"time\"][\"mean\"],\n",
    "                    \"cost_per_inference\": cost_per_inference,\n",
    "                    \"time_per_inference\": time_per_inference,\n",
    "                    \"accuracy\": acc_mean,\n",
    "                    \"cube_volume\": vol,\n",
    "                    \"stats\": stats,\n",
    "                    \"model\": model_config.name\n",
    "                }\n",
    "\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e4898e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# PARETO, UTOPIA, KNEE, CUBE\n",
    "# ===============================\n",
    "\n",
    "def is_dominated(point1, point2):\n",
    "    # points: (C, T, A)\n",
    "    C1, T1, A1 = point1\n",
    "    C2, T2, A2 = point2\n",
    "    non_worse = (C2 <= C1) and (T2 <= T1) and (A2 >= A1)\n",
    "    strictly_better = (C2 < C1) or (T2 < T1) or (A2 > A1)\n",
    "    return non_worse and strictly_better\n",
    "\n",
    "\n",
    "def find_pareto_frontier_mc(model_config, C_max_per_inference, T_max_per_inference, k_max=200, mc_trials=500, \n",
    "                           parallel_factor=8, seed=42):\n",
    "    \"\"\"Find Pareto frontier using per-inference constraints.\"\"\"\n",
    "    print(f\"Finding Pareto frontier with per-inference constraints...\")\n",
    "    \n",
    "    feasible_points = []\n",
    "    \n",
    "    for k in range(1, k_max + 1):\n",
    "        if k % 20 == 0:\n",
    "            print(f\"  k={k}/{k_max}\")\n",
    "            \n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials, parallel_factor, seed + k)\n",
    "        \n",
    "        # Calculate per-inference metrics\n",
    "        cost_per_inference = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inference = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        acc_mean = stats[\"acc\"][\"mean\"]\n",
    "        \n",
    "        # Check per-inference constraints\n",
    "        if (cost_per_inference <= C_max_per_inference and \n",
    "            time_per_inference <= T_max_per_inference):\n",
    "            \n",
    "            # Store both per-inference and total metrics\n",
    "            feasible_points.append((\n",
    "                k, \n",
    "                cost_per_inference, \n",
    "                time_per_inference, \n",
    "                acc_mean, \n",
    "                stats,\n",
    "                stats[\"cost\"][\"mean\"],  # total_cost\n",
    "                stats[\"time\"][\"mean\"]   # total_time\n",
    "            ))\n",
    "\n",
    "    if not feasible_points:\n",
    "        return None\n",
    "\n",
    "    # Pareto filtering based on per-inference values\n",
    "    pareto = []\n",
    "    for i, (k1, C1, T1, A1, stats1, tc1, tt1) in enumerate(feasible_points):\n",
    "        dominated = False\n",
    "        for j, (k2, C2, T2, A2, stats2, tc2, tt2) in enumerate(feasible_points):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if is_dominated((C1, T1, A1), (C2, T2, A2)):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto.append((k1, C1, T1, A1, stats1, tc1, tt1))\n",
    "    \n",
    "    pareto.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Utopia-closest selection based on per-inference metrics\n",
    "    def utopia_dist(C, T, A):\n",
    "        return np.linalg.norm([C / C_max_per_inference, T / T_max_per_inference, 1 - A])\n",
    "\n",
    "    best_item = min(pareto, key=lambda p: utopia_dist(p[1], p[2], p[3]))\n",
    "    k_best, Cb, Tb, Ab, stats_best, tc_best, tt_best = best_item\n",
    "\n",
    "    return {\n",
    "        \"k\": k_best,\n",
    "        \"cost_per_inference\": Cb,\n",
    "        \"time_per_inference\": Tb,\n",
    "        \"total_cost\": tc_best,\n",
    "        \"total_time\": tt_best,\n",
    "        \"accuracy\": Ab,\n",
    "        \"stats\": stats_best,\n",
    "        \"pareto_points\": [(k, C, T, A) for k, C, T, A, _, _, _ in pareto],\n",
    "        \"pareto_count\": len(pareto),\n",
    "        \"feasible_points\": len(feasible_points),\n",
    "        \"distance\": utopia_dist(Cb, Tb, Ab),\n",
    "        \"model\": model_config.name\n",
    "    }\n",
    "\n",
    "\n",
    "def find_knee_point(pareto_points, C_max_per_inference, T_max_per_inference):\n",
    "    \"\"\"Find knee point using per-inference normalization.\"\"\"\n",
    "    if pareto_points is None or len(pareto_points) < 3:\n",
    "        return None\n",
    "    \n",
    "    # Normalize based on per-inference constraints\n",
    "    P = np.array([[C / C_max_per_inference, T / T_max_per_inference, A] for _, C, T, A in pareto_points])\n",
    "    start = P[0]\n",
    "    end = P[-1]\n",
    "    v = end - start\n",
    "    vn = np.linalg.norm(v)\n",
    "    if vn == 0:\n",
    "        return pareto_points[len(pareto_points)//2]\n",
    "\n",
    "    v_unit = v / vn\n",
    "    max_d = -1\n",
    "    max_i = 0\n",
    "    for i in range(1, len(P)-1):\n",
    "        w = P[i] - start\n",
    "        proj = np.dot(w, v_unit) * v_unit\n",
    "        perp = w - proj\n",
    "        d = np.linalg.norm(perp)\n",
    "        if d > max_d:\n",
    "            max_d = d\n",
    "            max_i = i\n",
    "    return pareto_points[max_i]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# UPDATED COMPARISON WRAPPER\n",
    "# ===============================\n",
    "\n",
    "def compare_methods_mc(model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max=200, mc_trials=500, \n",
    "                      parallel_factor=8, seed=42):\n",
    "    \"\"\"Compare optimization methods using per-inference constraints.\"\"\"\n",
    "    print(f\"\\nðŸ”„ Running Monte Carlo comparison for {model_config.name}\")\n",
    "    print(f\"   Per-inference limits: C=${C_max_per_inference:.4f}, T={T_max_per_inference:.3f}s\")\n",
    "    print(f\"   MC trials: {mc_trials}, k_max: {k_max}, P: {parallel_factor}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    acc_res = find_accuracy_optimal_mc(model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max,\n",
    "                                      mc_trials, parallel_factor, seed)\n",
    "    \n",
    "    cube_res = find_maximum_cube_solution_mc(model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max,\n",
    "                                            mc_trials, parallel_factor, seed)\n",
    "    \n",
    "    pareto_res = find_pareto_frontier_mc(model_config, C_max_per_inference, T_max_per_inference, k_max,\n",
    "                                        mc_trials, parallel_factor, seed)\n",
    "    \n",
    "    knee_res = None\n",
    "    if pareto_res and pareto_res.get(\"pareto_points\"):\n",
    "        kp = find_knee_point(pareto_res[\"pareto_points\"], C_max_per_inference, T_max_per_inference)\n",
    "        if kp:\n",
    "            k_knee, Ck, Tk, Ak = kp\n",
    "            # Find stats for knee point\n",
    "            knee_stats = simulate_mc_with_model(k_knee, model_config, mc_trials, \n",
    "                                               parallel_factor, seed + k_knee)\n",
    "            knee_res = {\n",
    "                \"k\": k_knee, \n",
    "                \"cost_per_inference\": Ck,\n",
    "                \"time_per_inference\": Tk,\n",
    "                \"total_cost\": knee_stats[\"cost\"][\"mean\"],\n",
    "                \"total_time\": knee_stats[\"time\"][\"mean\"],\n",
    "                \"accuracy\": Ak,\n",
    "                \"stats\": knee_stats,\n",
    "                \"type\": \"knee_point\"\n",
    "            }\n",
    "    \n",
    "    return acc_res, cube_res, pareto_res, knee_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721c000",
   "metadata": {},
   "source": [
    "# Viz 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "515fd546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Monte Carlo Inference Scaling Optimization\n",
      "   Now with PER-INFERENCE constraints and proper MC averaging!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f1521778c54e8faeebef6bd2aee226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model', options=('gpt5', 'gpt5-mini', 'gpt5-nano', 'nvidia-nemotroâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min, k_max=200, mc_trials=300, parallel_factor=None, seed=42)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# UPDATED INTERACTIVE VISUALIZATION\n",
    "# ===============================\n",
    "\n",
    "def update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min, k_max=200, \n",
    "                     mc_trials=300, parallel_factor=None, seed=42):\n",
    "    \"\"\"Updated visualization using per-inference constraints.\"\"\"\n",
    "    model_config = MODEL_CONFIGS[selected_model]\n",
    "    if parallel_factor is None:\n",
    "        parallel_factor = model_config.default_parallel\n",
    "\n",
    "    print(f\"ðŸ¤– {model_config.name} | P={parallel_factor} | MC={mc_trials}\")\n",
    "    print(f\"   Costs: ${model_config.c_in*1e6:.2f}/M in, ${model_config.c_out*1e6:.2f}/M out\")\n",
    "    print(f\"   Times: {model_config.t_in*1e6:.0f}Î¼s/in tok, {model_config.t_out*1e6:.0f}Î¼s/out tok\")\n",
    "    print(f\"   ACC ~ N({model_config.acc_mean:.3f}, {model_config.acc_std:.3f})\")\n",
    "    print(f\"   Per-inference limits: C=${C_max_per_inference:.4f}, T={T_max_per_inference:.3f}s, ACC_min={acc_min:.3f}\")\n",
    "\n",
    "    # Generate response curves using Monte Carlo\n",
    "    print(\"\\nðŸ“Š Generating response curves...\")\n",
    "    ks = np.arange(1, min(k_max + 1, 51))  # Limit for visualization performance\n",
    "    Cs_mean, Cs_std, Ts_mean, Ts_std, As_mean, As_std = [], [], [], [], [], []\n",
    "    Cs_per_inf, Ts_per_inf = [], []  # Per-inference metrics\n",
    "    \n",
    "    for i, k in enumerate(ks):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"   k={k}/{len(ks)}\")\n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials//2, parallel_factor, seed + k)\n",
    "        \n",
    "        # Total metrics\n",
    "        Cs_mean.append(stats[\"cost\"][\"mean\"])\n",
    "        Cs_std.append(stats[\"cost\"][\"std\"])\n",
    "        Ts_mean.append(stats[\"time\"][\"mean\"])\n",
    "        Ts_std.append(stats[\"time\"][\"std\"])\n",
    "        As_mean.append(stats[\"acc\"][\"mean\"])\n",
    "        As_std.append(stats[\"acc\"][\"std\"])\n",
    "        \n",
    "        # Per-inference metrics\n",
    "        cost_per_inf = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inf = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        Cs_per_inf.append(cost_per_inf)\n",
    "        Ts_per_inf.append(time_per_inf)\n",
    "\n",
    "    Cs_mean, Ts_mean, As_mean = np.array(Cs_mean), np.array(Ts_mean), np.array(As_mean)\n",
    "    Cs_std, Ts_std, As_std = np.array(Cs_std), np.array(Ts_std), np.array(As_std)\n",
    "    Cs_per_inf, Ts_per_inf = np.array(Cs_per_inf), np.array(Ts_per_inf)\n",
    "\n",
    "    # Run optimization methods with per-inference constraints\n",
    "    acc_res, cube_res, pareto_res, knee_res = compare_methods_mc(\n",
    "        model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max, mc_trials, parallel_factor, seed\n",
    "    )\n",
    "\n",
    "    # Visualization with per-inference feasibility\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # 3D Plot using total costs/times but per-inference feasibility\n",
    "    ax1 = fig.add_subplot(221, projection=\"3d\")\n",
    "    feas = (Cs_per_inf <= C_max_per_inference) & (Ts_per_inf <= T_max_per_inference) & (As_mean >= acc_min)\n",
    "    \n",
    "    # Cube volume based on per-inference goodness\n",
    "    gC = np.clip(1 - Cs_per_inf / C_max_per_inference, 0, 1)\n",
    "    gT = np.clip(1 - Ts_per_inf / T_max_per_inference, 0, 1)\n",
    "    gA = np.clip(As_mean, 0, 1)\n",
    "    cube = gC * gT * gA\n",
    "    \n",
    "    scatter = ax1.scatter(Cs_mean, Ts_mean, As_mean, c=cube, cmap=\"plasma\", s=30, alpha=0.8)\n",
    "    ax1.plot(Cs_mean, Ts_mean, As_mean, color=\"green\", lw=1, alpha=0.5, label=\"MC Trajectory\")\n",
    "    cbar = plt.colorbar(scatter, ax=ax1, shrink=0.6, pad=0.1)\n",
    "    cbar.set_label(\"Cube Volume (per-inf)\")\n",
    "\n",
    "    # Add constraint planes - these are now derived from per-inference limits\n",
    "    max_feasible_k = len(ks)\n",
    "    Cg, Tg = np.meshgrid(\n",
    "        np.linspace(0, C_max_per_inference * max_feasible_k, 10), \n",
    "        np.linspace(0, T_max_per_inference * max_feasible_k, 10)\n",
    "    )\n",
    "    Ag = np.full_like(Cg, acc_min)\n",
    "    ax1.plot_surface(Cg, Tg, Ag, color=\"green\", alpha=0.15, label=\"ACC constraint\")\n",
    "\n",
    "    # Mark optimal solutions using total costs/times for visualization\n",
    "    def mark_mc(ax, res, color, marker, label):\n",
    "        if res:\n",
    "            total_cost = res.get(\"total_cost\", res.get(\"cost\", 0))\n",
    "            total_time = res.get(\"total_time\", res.get(\"time\", 0))\n",
    "            ax.scatter(total_cost, total_time, res[\"accuracy\"], \n",
    "                      color=color, s=140, edgecolors=\"black\", marker=marker, \n",
    "                      linewidth=2, label=f\"{label} k={res['k']}\")\n",
    "\n",
    "    mark_mc(ax1, acc_res, \"gold\", \"o\", \"Accuracy-opt\")\n",
    "    mark_mc(ax1, cube_res, \"orange\", \"^\", \"Cube-opt\")\n",
    "    mark_mc(ax1, pareto_res, \"red\", \"D\", \"Utopia\")\n",
    "    mark_mc(ax1, knee_res, \"purple\", \"s\", \"Knee\")\n",
    "\n",
    "    ax1.set_xlabel(\"Total Cost ($)\")\n",
    "    ax1.set_ylabel(\"Total Time (s)\")\n",
    "    ax1.set_zlabel(\"Accuracy\")\n",
    "    ax1.set_title(f\"3D MC (Per-Inference Constraints): {model_config.name}\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # 2D plots with per-inference constraint lines\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.errorbar(ks, As_mean, yerr=As_std, lw=1.2, alpha=0.7, label=\"Accuracy Â± Ïƒ\")\n",
    "    ax2.scatter(ks[feas], As_mean[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax2.axhline(acc_min, ls=\"--\", color=\"red\", label=f\"ACC_min={acc_min:.2f}\")\n",
    "    if acc_res: ax2.scatter([acc_res[\"k\"]], [acc_res[\"accuracy\"]], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax2.scatter([cube_res[\"k\"]], [cube_res[\"accuracy\"]], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax2.scatter([pareto_res[\"k\"]], [pareto_res[\"accuracy\"]], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax2.scatter([knee_res[\"k\"]], [knee_res[\"accuracy\"]], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax2.set_xlabel(\"k\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Accuracy vs k (Per-Inf Constraints)\")\n",
    "\n",
    "    # ax3 = fig.add_subplot(223)\n",
    "    # ax3.errorbar(ks, Cs_per_inf, lw=1.2, alpha=0.7, label=\"Cost per inference\")\n",
    "    # ax3.scatter(ks[feas], Cs_per_inf[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    # ax3.axhline(C_max_per_inference, ls=\"--\", color=\"red\", label=f\"C_max/inf=${C_max_per_inference:.4f}\")\n",
    "    # if acc_res: ax3.scatter([acc_res[\"k\"]], [acc_res.get(\"cost_per_inference\", 0)], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    # if cube_res: ax3.scatter([cube_res[\"k\"]], [cube_res.get(\"cost_per_inference\", 0)], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    # if pareto_res: ax3.scatter([pareto_res[\"k\"]], [pareto_res.get(\"cost_per_inference\", 0)], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    # if knee_res: ax3.scatter([knee_res[\"k\"]], [knee_res.get(\"cost_per_inference\", 0)], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    # ax3.set_xlabel(\"k\")\n",
    "    # ax3.set_ylabel(\"Cost per inference ($)\")\n",
    "    # ax3.grid(True, alpha=0.3)\n",
    "    # ax3.legend()\n",
    "    # ax3.set_title(\"Cost per inference vs k\")\n",
    "\n",
    "    ax4 = fig.add_subplot(224)\n",
    "    ax4.errorbar(ks, Ts_per_inf, lw=1.2, alpha=0.7, label=\"Time per inference\")\n",
    "    ax4.scatter(ks[feas], Ts_per_inf[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax4.axhline(T_max_per_inference, ls=\"--\", color=\"blue\", label=f\"T_max/inf={T_max_per_inference:.3f}s\")\n",
    "    if acc_res: ax4.scatter([acc_res[\"k\"]], [acc_res.get(\"time_per_inference\", 0)], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax4.scatter([cube_res[\"k\"]], [cube_res.get(\"time_per_inference\", 0)], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax4.scatter([pareto_res[\"k\"]], [pareto_res.get(\"time_per_inference\", 0)], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax4.scatter([knee_res[\"k\"]], [knee_res.get(\"time_per_inference\", 0)], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax4.set_xlabel(\"k\")\n",
    "    ax4.set_ylabel(\"Time per inference (s)\")\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend()\n",
    "    ax4.set_title(\"Time per inference vs k\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Enhanced text summary with per-inference metrics\n",
    "    print(\"\\nðŸ“‹ MONTE CARLO OPTIMIZATION RESULTS (Per-Inference Constraints)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if acc_res:\n",
    "        stats = acc_res[\"stats\"]\n",
    "        print(f\"ðŸŽ¯ Accuracy-Optimal: k={acc_res['k']}\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inference: ${acc_res['cost_per_inference']:.4f}, {acc_res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${acc_res['total_cost']:.3f}, {acc_res['total_time']:.1f}s\")\n",
    "    \n",
    "    if cube_res:\n",
    "        stats = cube_res[\"stats\"]\n",
    "        print(f\"\\nðŸ”¶ Cube-Optimal: k={cube_res['k']} (vol={cube_res['cube_volume']:.3f})\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inference: ${cube_res['cost_per_inference']:.4f}, {cube_res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${cube_res['total_cost']:.3f}, {cube_res['total_time']:.1f}s\")\n",
    "    \n",
    "    if pareto_res:\n",
    "        stats = pareto_res[\"stats\"]\n",
    "        print(f\"\\nðŸ”´ Utopia-Closest: k={pareto_res['k']} (dist={pareto_res['distance']:.3f})\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inference: ${pareto_res['cost_per_inference']:.4f}, {pareto_res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${pareto_res['total_cost']:.3f}, {pareto_res['total_time']:.1f}s\")\n",
    "        print(f\"   Pareto points: {pareto_res['pareto_count']}/{pareto_res['feasible_points']}\")\n",
    "    \n",
    "    if knee_res:\n",
    "        stats = knee_res[\"stats\"]\n",
    "        print(f\"\\nðŸŸ£ Knee-Point: k={knee_res['k']}\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inference: ${knee_res['cost_per_inference']:.4f}, {knee_res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${knee_res['total_cost']:.3f}, {knee_res['total_time']:.1f}s\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# UPDATED WIDGET WITH PER-INFERENCE CONSTRAINTS\n",
    "# ===============================\n",
    "\n",
    "# Update budget defaults to per-inference values\n",
    "C_max_per_inference_default = 0.050  # $0.05 per inference \n",
    "T_max_per_inference_default = 5.0    # 5 seconds per inference\n",
    "\n",
    "print(\"ðŸš€ Monte Carlo Inference Scaling Optimization\")\n",
    "print(\"   Now with PER-INFERENCE constraints and proper MC averaging!\")\n",
    "\n",
    "widgets.interact(\n",
    "    update_visuals_mc,\n",
    "    selected_model=widgets.Dropdown(options=list(MODEL_CONFIGS.keys()),\n",
    "                                    value='gpt5', description='Model'),\n",
    "    C_max_per_inference=widgets.FloatSlider(min=0.001, max=0.200, step=0.001,\n",
    "                              value=C_max_per_inference_default, description=\"Max Cost/Inf ($)\"),\n",
    "    T_max_per_inference=widgets.FloatSlider(min=0.5, max=30.0, step=0.1,\n",
    "                              value=T_max_per_inference_default, description=\"Max Time/Inf (s)\"),\n",
    "    acc_min=widgets.FloatSlider(min=0.70, max=0.99, step=0.01,\n",
    "                                value=0.83, description=\"Min ACC\"),\n",
    "    k_max=widgets.IntSlider(min=2, max=16*16, step=2, value=2**5, description=\"k_max\"),\n",
    "    mc_trials=widgets.IntSlider(min=100, max=500, step=10, value=100, description=\"MC Trials\"),\n",
    "    parallel_factor=widgets.IntSlider(min=1, max=256, step=1,\n",
    "                                      value=MODEL_CONFIGS['gpt5'].default_parallel,\n",
    "                                      description=\"Parallelism (P)\"),\n",
    "    # seed=widgets.IntText(value=42, description=\"Seed\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da99989",
   "metadata": {},
   "source": [
    "# viz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5f841c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Monte Carlo Inference Scaling Optimization\n",
      "   With PER-INFERENCE constraints and colored 3D FEASIBLE CUBE visualization!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a319657340ec47c5a4e5bd88e3497b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model', options=('gpt5', 'gpt5-mini', 'gpt5-nano', 'nvidia-nemotroâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min, k_max=200, mc_trials=300, parallel_factor=None, seed=42)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# UPDATED INTERACTIVE VISUALIZATION WITH COLORED CONSTRAINTS & BOLDED CUBE\n",
    "# ===============================\n",
    "# UPDATED INTERACTIVE VISUALIZATION WITH CONSTRAINT SURFACES & BOLDED CUBE\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min,\n",
    "                     k_max=200, mc_trials=300, parallel_factor=None, seed=42):\n",
    "    \"\"\"Visualization with colored constraints + bolded feasible cube.\"\"\"\n",
    "    model_config = MODEL_CONFIGS[selected_model]\n",
    "    if parallel_factor is None:\n",
    "        parallel_factor = model_config.default_parallel\n",
    "\n",
    "    print(f\"ðŸ¤– {model_config.name} | P={parallel_factor} | MC={mc_trials}\")\n",
    "    print(f\"   Costs: ${model_config.c_in*1e6:.2f}/M in, ${model_config.c_out*1e6:.2f}/M out\")\n",
    "    print(f\"   Times: {model_config.t_in*1e6:.0f}Î¼s/in tok, {model_config.t_out*1e6:.0f}Î¼s/out tok\")\n",
    "    print(f\"   ACC ~ N({model_config.acc_mean:.3f}, {model_config.acc_std:.3f})\")\n",
    "    print(f\"   Per-inference limits: C=${C_max_per_inference:.4f}, T={T_max_per_inference:.3f}s, ACC_min={acc_min:.3f}\")\n",
    "\n",
    "    # Generate response curves using Monte Carlo\n",
    "    print(\"\\nðŸ“Š Generating response curves...\")\n",
    "    ks = np.arange(1, min(k_max + 1, 51))\n",
    "    Cs_mean, Ts_mean, As_mean = [], [], []\n",
    "    Cs_std, Ts_std, As_std = [], [], []\n",
    "    Cs_per_inf, Ts_per_inf = [], []\n",
    "\n",
    "    for i, k in enumerate(ks):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"   k={k}/{len(ks)}\")\n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials//2, parallel_factor, seed + k)\n",
    "\n",
    "        Cs_mean.append(stats[\"cost\"][\"mean\"])\n",
    "        Cs_std.append(stats[\"cost\"][\"std\"])\n",
    "        Ts_mean.append(stats[\"time\"][\"mean\"])\n",
    "        Ts_std.append(stats[\"time\"][\"std\"])\n",
    "        As_mean.append(stats[\"acc\"][\"mean\"])\n",
    "        As_std.append(stats[\"acc\"][\"std\"])\n",
    "\n",
    "        # Per-inference metrics\n",
    "        cost_per_inf = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inf = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        Cs_per_inf.append(cost_per_inf)\n",
    "        Ts_per_inf.append(time_per_inf)\n",
    "\n",
    "    Cs_mean, Ts_mean, As_mean = np.array(Cs_mean), np.array(Ts_mean), np.array(As_mean)\n",
    "    Cs_std, Ts_std, As_std = np.array(Cs_std), np.array(Ts_std), np.array(As_std)\n",
    "    Cs_per_inf, Ts_per_inf = np.array(Cs_per_inf), np.array(Ts_per_inf)\n",
    "\n",
    "    # Run optimization methods\n",
    "    acc_res, cube_res, pareto_res, knee_res = compare_methods_mc(\n",
    "        model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max, mc_trials, parallel_factor, seed\n",
    "    )\n",
    "\n",
    "    # === Visualization ===\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    ax1 = fig.add_subplot(221, projection=\"3d\")\n",
    "\n",
    "    feas = (Cs_per_inf <= C_max_per_inference) & (Ts_per_inf <= T_max_per_inference) & (As_mean >= acc_min)\n",
    "\n",
    "    # Cube-volume color\n",
    "    gC = np.clip(1 - Cs_per_inf / C_max_per_inference, 0, 1)\n",
    "    gT = np.clip(1 - Ts_per_inf / T_max_per_inference, 0, 1)\n",
    "    gA = np.clip(As_mean, 0, 1)\n",
    "    cube = gC * gT * gA\n",
    "\n",
    "    # Scatter MC points\n",
    "    sc = ax1.scatter(Cs_mean, Ts_mean, As_mean, c=cube, cmap=\"plasma\", s=40, alpha=0.8)\n",
    "    ax1.plot(Cs_mean, Ts_mean, As_mean, color=\"gray\", lw=1, alpha=0.5, label=\"MC trajectory\")\n",
    "    plt.colorbar(sc, ax=ax1, shrink=0.6, pad=0.1, label=\"Cube Volume\")\n",
    "\n",
    "    # === Add feasible cube with colored constraint planes ===\n",
    "    Cmax = C_max_per_inference * len(ks)\n",
    "    Tmax = T_max_per_inference * len(ks)\n",
    "    Amin = acc_min\n",
    "    Cg, Tg = np.meshgrid(np.linspace(0, Cmax, 20), np.linspace(0, Tmax, 20))\n",
    "\n",
    "    # Constraint planes\n",
    "    # Cost plane (red)\n",
    "    ax1.plot_surface(np.full_like(Cg, Cmax), Tg, np.full_like(Cg, Amin + (1 - Amin)),\n",
    "                     color=\"tomato\", alpha=0.20)\n",
    "\n",
    "    # Time plane (blue)\n",
    "    ax1.plot_surface(Cg, np.full_like(Tg, Tmax), np.full_like(Cg, Amin + (1 - Amin)),\n",
    "                     color=\"royalblue\", alpha=0.20)\n",
    "\n",
    "    # Accuracy plane (green)\n",
    "    ax1.plot_surface(Cg, Tg, np.full_like(Cg, Amin),\n",
    "                     color=\"limegreen\", alpha=0.25)\n",
    "\n",
    "    # Cube faces (transparent fill)\n",
    "    verts = [\n",
    "        [0, 0, Amin], [Cmax, 0, Amin], [Cmax, Tmax, Amin], [0, Tmax, Amin],\n",
    "        [0, 0, 1], [Cmax, 0, 1], [Cmax, Tmax, 1], [0, Tmax, 1]\n",
    "    ]\n",
    "    faces = [\n",
    "        [verts[j] for j in [0,1,2,3]],\n",
    "        [verts[j] for j in [4,5,6,7]],\n",
    "        [verts[j] for j in [0,1,5,4]],\n",
    "        [verts[j] for j in [2,3,7,6]],\n",
    "        [verts[j] for j in [1,2,6,5]],\n",
    "        [verts[j] for j in [4,7,3,0]]\n",
    "    ]\n",
    "    ax1.add_collection3d(Poly3DCollection(faces, color=\"lightgreen\", alpha=0.05))\n",
    "\n",
    "    # Cube edges (bold)\n",
    "    edge_color = \"black\"\n",
    "    edge_thick = 1.8\n",
    "    for X in [0, Cmax]:\n",
    "        for Y in [0, Tmax]:\n",
    "            ax1.plot([X, X], [Y, Y], [Amin, 1], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "    for X in [0, Cmax]:\n",
    "        for Z in [Amin, 1]:\n",
    "            ax1.plot([X, X], [0, Tmax], [Z, Z], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "    for Y in [0, Tmax]:\n",
    "        for Z in [Amin, 1]:\n",
    "            ax1.plot([0, Cmax], [Y, Y], [Z, Z], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "\n",
    "    # Mark optimal points\n",
    "    def mark_mc(ax, res, color, marker, label):\n",
    "        if res:\n",
    "            ax.scatter(res.get(\"total_cost\", res.get(\"cost\", 0)),\n",
    "                       res.get(\"total_time\", res.get(\"time\", 0)),\n",
    "                       res[\"accuracy\"], color=color, edgecolors=\"black\",\n",
    "                       s=140, marker=marker, linewidth=1.5,\n",
    "                       label=f\"{label} k={res['k']}\")\n",
    "\n",
    "    mark_mc(ax1, acc_res, \"gold\", \"o\", \"Accuracy-opt\")\n",
    "    mark_mc(ax1, cube_res, \"orange\", \"^\", \"Cube-opt\")\n",
    "    mark_mc(ax1, pareto_res, \"red\", \"D\", \"Utopia\")\n",
    "    mark_mc(ax1, knee_res, \"purple\", \"s\", \"Knee\")\n",
    "\n",
    "    ax1.set_xlabel(\"Cost ($)\")\n",
    "    ax1.set_ylabel(\"Time (/s)\")\n",
    "    ax1.set_zlabel(\"Performance (ACC)\")\n",
    "    ax1.set_xlim(0, Cmax * 1.05)\n",
    "    ax1.set_ylim(0, Tmax * 1.05)\n",
    "    ax1.set_zlim(Amin - 0.02, 1.0)\n",
    "    ax1.set_title(f\"3D Feasible Cube â€” {model_config.name}\")\n",
    "    ax1.legend(loc=\"upper left\", fontsize=8)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2D Accuracy vs k\n",
    "    # -------------------------\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.errorbar(ks, As_mean, yerr=As_std, lw=1.2, alpha=0.7, label=\"Accuracy Â± Ïƒ\")\n",
    "    ax2.scatter(ks[feas], As_mean[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax2.axhline(acc_min, ls=\"--\", color=\"red\", label=f\"ACC_min={acc_min:.2f}\")\n",
    "    if acc_res: ax2.scatter([acc_res[\"k\"]], [acc_res[\"accuracy\"]], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax2.scatter([cube_res[\"k\"]], [cube_res[\"accuracy\"]], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax2.scatter([pareto_res[\"k\"]], [pareto_res[\"accuracy\"]], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax2.scatter([knee_res[\"k\"]], [knee_res[\"accuracy\"]], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax2.set_xlabel(\"k\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Accuracy vs k (Per-Inf Constraints)\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 2D Time per inference\n",
    "    # -------------------------\n",
    "    ax4 = fig.add_subplot(224)\n",
    "    ax4.errorbar(ks, Ts_per_inf, lw=1.2, alpha=0.7, label=\"Time per inference\")\n",
    "    ax4.scatter(ks[feas], Ts_per_inf[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax4.axhline(T_max_per_inference, ls=\"--\", color=\"blue\", label=f\"T_max/inf={T_max_per_inference:.3f}s\")\n",
    "    if acc_res: ax4.scatter([acc_res[\"k\"]], [acc_res.get(\"time_per_inference\", 0)], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax4.scatter([cube_res[\"k\"]], [cube_res.get(\"time_per_inference\", 0)], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax4.scatter([pareto_res[\"k\"]], [pareto_res.get(\"time_per_inference\", 0)], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax4.scatter([knee_res[\"k\"]], [knee_res.get(\"time_per_inference\", 0)], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax4.set_xlabel(\"k\")\n",
    "    ax4.set_ylabel(\"Time per inference (s)\")\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend()\n",
    "    ax4.set_title(\"Time per inference vs k\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------\n",
    "    # Text Summary\n",
    "    # -------------------------\n",
    "    print(\"\\nðŸ“‹ MONTE CARLO OPTIMIZATION RESULTS (Per-Inference Constraints)\")\n",
    "    print(\"=\"*70)\n",
    "    def print_res(label, emoji, res, extra=\"\"):\n",
    "        if not res: return\n",
    "        stats = res[\"stats\"]\n",
    "        print(f\"\\n{emoji} {label}: k={res['k']} {extra}\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inf: ${res['cost_per_inference']:.4f}, {res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${res['total_cost']:.3f}, {res['total_time']:.1f}s\")\n",
    "\n",
    "    print_res(\"Accuracy-Optimal\", \"ðŸŽ¯\", acc_res)\n",
    "    print_res(\"Cube-Optimal\", \"ðŸ”¶\", cube_res, f\"(vol={cube_res.get('cube_volume', 0):.3f})\")\n",
    "    print_res(\"Utopia-Closest\", \"ðŸ”´\", pareto_res, f\"(dist={pareto_res.get('distance', 0):.3f})\")\n",
    "    print_res(\"Knee-Point\", \"ðŸŸ£\", knee_res)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# INTERACTIVE WIDGET SETUP\n",
    "# ===============================\n",
    "C_max_per_inference_default = 0.050\n",
    "T_max_per_inference_default = 5.0\n",
    "\n",
    "print(\"ðŸš€ Monte Carlo Inference Scaling Optimization\")\n",
    "print(\"   With PER-INFERENCE constraints and colored 3D FEASIBLE CUBE visualization!\")\n",
    "\n",
    "widgets.interact(\n",
    "    update_visuals_mc,\n",
    "    selected_model=widgets.Dropdown(options=list(MODEL_CONFIGS.keys()),\n",
    "                                    value='gpt5', description='Model'),\n",
    "    C_max_per_inference=widgets.FloatSlider(min=0.001, max=0.900, step=0.001,\n",
    "                              value=C_max_per_inference_default, description=\"Max Cost/Inf ($)\"),\n",
    "    T_max_per_inference=widgets.FloatSlider(min=10, max=6000.0, step=0.1,\n",
    "                              value=T_max_per_inference_default, description=\"Max Time/Inf (s)\"),\n",
    "    acc_min=widgets.FloatSlider(min=0.70, max=0.99, step=0.01,\n",
    "                                value=0.83, description=\"Min ACC\"),\n",
    "    k_max=widgets.IntSlider(min=2, max=16*16, step=2, value=2**5, description=\"k_max\"),\n",
    "    mc_trials=widgets.IntSlider(min=300, max=500, step=10, value=100, description=\"MC Trials\"),\n",
    "    parallel_factor=widgets.IntSlider(min=1, max=256, step=1,\n",
    "                                      value=MODEL_CONFIGS['gpt5'].default_parallel,\n",
    "                                      description=\"Parallelism (P)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a1ce2",
   "metadata": {},
   "source": [
    "# viz 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f11477bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Monte Carlo Inference Scaling Optimization â€” One Figure per Plot!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1fdc2ebfb94384820092d7783ab237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model', options=('gpt5', 'gpt5-mini', 'gpt5-nano', 'nvidia-nemotroâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min, k_max=200, mc_trials=300, parallel_factor=None, seed=42)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# UPDATED VISUALIZATION â€” ONE FIGURE PER PLOT\n",
    "# ===============================\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def update_visuals_mc(selected_model, C_max_per_inference, T_max_per_inference, acc_min,\n",
    "                     k_max=200, mc_trials=300, parallel_factor=None, seed=42):\n",
    "    \"\"\"Generate three separate figures instead of one combined image.\"\"\"\n",
    "    model_config = MODEL_CONFIGS[selected_model]\n",
    "    if parallel_factor is None:\n",
    "        parallel_factor = model_config.default_parallel\n",
    "\n",
    "    print(f\"ðŸ¤– {model_config.name} | P={parallel_factor} | MC={mc_trials}\")\n",
    "    print(f\"   Costs: ${model_config.c_in*1e6:.2f}/M in, ${model_config.c_out*1e6:.2f}/M out\")\n",
    "    print(f\"   Times: {model_config.t_in*1e6:.0f}Î¼s/in tok, {model_config.t_out*1e6:.0f}Î¼s/out tok\")\n",
    "    print(f\"   ACC ~ N({model_config.acc_mean:.3f}, {model_config.acc_std:.3f})\")\n",
    "    print(f\"   Per-inference limits: C=${C_max_per_inference:.4f}, T={T_max_per_inference:.3f}s, ACC_min={acc_min:.3f}\")\n",
    "\n",
    "    # Monte Carlo simulations\n",
    "    print(\"\\nðŸ“Š Generating response curves...\")\n",
    "    ks = np.arange(1, min(k_max + 1, 51))\n",
    "    Cs_mean, Ts_mean, As_mean = [], [], []\n",
    "    Cs_std, Ts_std, As_std = [], [], []\n",
    "    Cs_per_inf, Ts_per_inf = [], []\n",
    "\n",
    "    for i, k in enumerate(ks):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"   k={k}/{len(ks)}\")\n",
    "        stats = simulate_mc_with_model(k, model_config, mc_trials//2, parallel_factor, seed + k)\n",
    "\n",
    "        Cs_mean.append(stats[\"cost\"][\"mean\"])\n",
    "        Cs_std.append(stats[\"cost\"][\"std\"])\n",
    "        Ts_mean.append(stats[\"time\"][\"mean\"])\n",
    "        Ts_std.append(stats[\"time\"][\"std\"])\n",
    "        As_mean.append(stats[\"acc\"][\"mean\"])\n",
    "        As_std.append(stats[\"acc\"][\"std\"])\n",
    "\n",
    "        cost_per_inf = stats[\"cost\"][\"mean\"] / k\n",
    "        time_per_inf = stats[\"time\"][\"mean\"] / k if parallel_factor == 1 else stats[\"time\"][\"mean\"] / min(k, parallel_factor)\n",
    "        Cs_per_inf.append(cost_per_inf)\n",
    "        Ts_per_inf.append(time_per_inf)\n",
    "\n",
    "    Cs_mean, Ts_mean, As_mean = np.array(Cs_mean), np.array(Ts_mean), np.array(As_mean)\n",
    "    Cs_std, Ts_std, As_std = np.array(Cs_std), np.array(Ts_std), np.array(As_std)\n",
    "    Cs_per_inf, Ts_per_inf = np.array(Cs_per_inf), np.array(Ts_per_inf)\n",
    "\n",
    "    # Run optimization methods\n",
    "    acc_res, cube_res, pareto_res, knee_res = compare_methods_mc(\n",
    "        model_config, C_max_per_inference, T_max_per_inference, acc_min, k_max, mc_trials, parallel_factor, seed\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # FIGURE 1 â€” 3D Feasible Cube\n",
    "    # =====================================================\n",
    "    fig1 = plt.figure(figsize=(8, 6))\n",
    "    ax1 = fig1.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    feas = (Cs_per_inf <= C_max_per_inference) & (Ts_per_inf <= T_max_per_inference) & (As_mean >= acc_min)\n",
    "    gC = np.clip(1 - Cs_per_inf / C_max_per_inference, 0, 1)\n",
    "    gT = np.clip(1 - Ts_per_inf / T_max_per_inference, 0, 1)\n",
    "    gA = np.clip(As_mean, 0, 1)\n",
    "    cube = gC * gT * gA\n",
    "\n",
    "    sc = ax1.scatter(Cs_mean, Ts_mean, As_mean, c=cube, cmap=\"plasma\", s=40, alpha=0.8)\n",
    "    ax1.plot(Cs_mean, Ts_mean, As_mean, color=\"gray\", lw=1, alpha=0.5, label=\"MC trajectory\")\n",
    "    plt.colorbar(sc, ax=ax1, shrink=0.6, pad=0.1, label=\"Cube Volume\")\n",
    "\n",
    "    Cmax = C_max_per_inference * len(ks)\n",
    "    Tmax = T_max_per_inference * len(ks)\n",
    "    Amin = acc_min\n",
    "    Cg, Tg = np.meshgrid(np.linspace(0, Cmax, 20), np.linspace(0, Tmax, 20))\n",
    "\n",
    "    # Constraint planes\n",
    "    ax1.plot_surface(np.full_like(Cg, Cmax), Tg, np.full_like(Cg, Amin + (1 - Amin)),\n",
    "                     color=\"tomato\", alpha=0.20)\n",
    "    ax1.plot_surface(Cg, np.full_like(Tg, Tmax), np.full_like(Cg, Amin + (1 - Amin)),\n",
    "                     color=\"royalblue\", alpha=0.20)\n",
    "    ax1.plot_surface(Cg, Tg, np.full_like(Cg, Amin),\n",
    "                     color=\"limegreen\", alpha=0.25)\n",
    "\n",
    "    # Cube faces and edges\n",
    "    verts = [\n",
    "        [0, 0, Amin], [Cmax, 0, Amin], [Cmax, Tmax, Amin], [0, Tmax, Amin],\n",
    "        [0, 0, 1], [Cmax, 0, 1], [Cmax, Tmax, 1], [0, Tmax, 1]\n",
    "    ]\n",
    "    faces = [\n",
    "        [verts[j] for j in [0,1,2,3]],\n",
    "        [verts[j] for j in [4,5,6,7]],\n",
    "        [verts[j] for j in [0,1,5,4]],\n",
    "        [verts[j] for j in [2,3,7,6]],\n",
    "        [verts[j] for j in [1,2,6,5]],\n",
    "        [verts[j] for j in [4,7,3,0]]\n",
    "    ]\n",
    "    ax1.add_collection3d(Poly3DCollection(faces, color=\"lightgreen\", alpha=0.05))\n",
    "\n",
    "    edge_color, edge_thick = \"black\", 1.8\n",
    "    for X in [0, Cmax]:\n",
    "        for Y in [0, Tmax]:\n",
    "            ax1.plot([X, X], [Y, Y], [Amin, 1], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "    for X in [0, Cmax]:\n",
    "        for Z in [Amin, 1]:\n",
    "            ax1.plot([X, X], [0, Tmax], [Z, Z], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "    for Y in [0, Tmax]:\n",
    "        for Z in [Amin, 1]:\n",
    "            ax1.plot([0, Cmax], [Y, Y], [Z, Z], color=edge_color, lw=edge_thick, alpha=0.9)\n",
    "\n",
    "    def mark_mc(ax, res, color, marker, label):\n",
    "        if res:\n",
    "            ax.scatter(res.get(\"total_cost\", res.get(\"cost\", 0)),\n",
    "                       res.get(\"total_time\", res.get(\"time\", 0)),\n",
    "                       res[\"accuracy\"], color=color, edgecolors=\"black\",\n",
    "                       s=140, marker=marker, linewidth=1.5,\n",
    "                       label=f\"{label} k={res['k']}\")\n",
    "\n",
    "    mark_mc(ax1, acc_res, \"gold\", \"o\", \"Accuracy-opt\")\n",
    "    mark_mc(ax1, cube_res, \"orange\", \"^\", \"Cube-opt\")\n",
    "    mark_mc(ax1, pareto_res, \"red\", \"D\", \"Utopia\")\n",
    "    mark_mc(ax1, knee_res, \"purple\", \"s\", \"Knee\")\n",
    "\n",
    "    ax1.set_xlabel(\"Cost ($)\")\n",
    "    ax1.set_ylabel(\"Time (s)\")\n",
    "    ax1.set_zlabel(\"Accuracy\")\n",
    "    ax1.set_title(f\"3D Feasible Cube â€” {model_config.name}\")\n",
    "    ax1.legend(loc=\"upper left\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fig1.savefig(f\"{model_config.name}_3D_cube.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    # =====================================================\n",
    "    # FIGURE 2 â€” Accuracy vs k\n",
    "    # =====================================================\n",
    "    fig2, ax2 = plt.subplots(figsize=(6, 4))\n",
    "    ax2.errorbar(ks, As_mean, yerr=As_std, lw=1.2, alpha=0.7, label=\"Accuracy Â± Ïƒ\")\n",
    "    ax2.scatter(ks[feas], As_mean[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax2.axhline(acc_min, ls=\"--\", color=\"red\", label=f\"ACC_min={acc_min:.2f}\")\n",
    "    if acc_res: ax2.scatter([acc_res[\"k\"]], [acc_res[\"accuracy\"]], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax2.scatter([cube_res[\"k\"]], [cube_res[\"accuracy\"]], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax2.scatter([pareto_res[\"k\"]], [pareto_res[\"accuracy\"]], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax2.scatter([knee_res[\"k\"]], [knee_res[\"accuracy\"]], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax2.set_xlabel(\"k\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    ax2.set_title(\"Accuracy vs k (Per-Inf Constraints)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fig2.savefig(f\"{model_config.name}_Accuracy_vs_k.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    # =====================================================\n",
    "    # FIGURE 3 â€” Time per Inference vs k\n",
    "    # =====================================================\n",
    "    fig3, ax3 = plt.subplots(figsize=(6, 4))\n",
    "    ax3.errorbar(ks, Ts_per_inf, lw=1.2, alpha=0.7, label=\"Time per inference\")\n",
    "    ax3.scatter(ks[feas], Ts_per_inf[feas], s=12, color=\"lightgreen\", alpha=0.7, label=\"Feasible\")\n",
    "    ax3.axhline(T_max_per_inference, ls=\"--\", color=\"blue\", label=f\"T_max/inf={T_max_per_inference:.3f}s\")\n",
    "    if acc_res: ax3.scatter([acc_res[\"k\"]], [acc_res.get(\"time_per_inference\", 0)], s=100, c=\"gold\", edgecolors=\"black\")\n",
    "    if cube_res: ax3.scatter([cube_res[\"k\"]], [cube_res.get(\"time_per_inference\", 0)], s=80, c=\"orange\", edgecolors=\"black\", marker=\"^\")\n",
    "    if pareto_res: ax3.scatter([pareto_res[\"k\"]], [pareto_res.get(\"time_per_inference\", 0)], s=80, c=\"red\", edgecolors=\"black\", marker=\"D\")\n",
    "    if knee_res: ax3.scatter([knee_res[\"k\"]], [knee_res.get(\"time_per_inference\", 0)], s=80, c=\"purple\", edgecolors=\"black\", marker=\"s\")\n",
    "    ax3.set_xlabel(\"k\")\n",
    "    ax3.set_ylabel(\"Time per inference (s)\")\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    ax3.set_title(\"Time per inference vs k\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fig3.savefig(f\"{model_config.name}_Time_vs_k.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    # =====================================================\n",
    "    # Text Summary\n",
    "    # =====================================================\n",
    "    print(\"\\nðŸ“‹ MONTE CARLO OPTIMIZATION RESULTS (Per-Inference Constraints)\")\n",
    "    print(\"=\"*70)\n",
    "    def print_res(label, emoji, res, extra=\"\"):\n",
    "        if not res: return\n",
    "        stats = res[\"stats\"]\n",
    "        print(f\"\\n{emoji} {label}: k={res['k']} {extra}\")\n",
    "        print(f\"   ACC: {stats['acc']['mean']:.3f} Â± {stats['acc']['std']:.3f}\")\n",
    "        print(f\"   Per-inf: ${res['cost_per_inference']:.4f}, {res['time_per_inference']:.3f}s\")\n",
    "        print(f\"   Total: ${res['total_cost']:.3f}, {res['total_time']:.1f}s\")\n",
    "\n",
    "    print_res(\"Accuracy-Optimal\", \"ðŸŽ¯\", acc_res)\n",
    "    print_res(\"Cube-Optimal\", \"ðŸ”¶\", cube_res, f\"(vol={cube_res.get('cube_volume', 0):.3f})\")\n",
    "    print_res(\"Utopia-Closest\", \"ðŸ”´\", pareto_res, f\"(dist={pareto_res.get('distance', 0):.3f})\")\n",
    "    print_res(\"Knee-Point\", \"ðŸŸ£\", knee_res)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# INTERACTIVE WIDGET SETUP\n",
    "# ===============================\n",
    "C_max_per_inference_default = 0.050\n",
    "T_max_per_inference_default = 5.0\n",
    "\n",
    "print(\"ðŸš€ Monte Carlo Inference Scaling Optimization â€” One Figure per Plot!\")\n",
    "\n",
    "widgets.interact(\n",
    "    update_visuals_mc,\n",
    "    selected_model=widgets.Dropdown(options=list(MODEL_CONFIGS.keys()),\n",
    "                                    value='gpt5', description='Model'),\n",
    "    C_max_per_inference=widgets.FloatSlider(min=0.001, max=0.900, step=0.001,\n",
    "                              value=C_max_per_inference_default, description=\"Max Cost/Inf ($)\"),\n",
    "    T_max_per_inference=widgets.FloatSlider(min=10, max=6000.0, step=0.1,\n",
    "                              value=T_max_per_inference_default, description=\"Max Time/Inf (s)\"),\n",
    "    acc_min=widgets.FloatSlider(min=0.70, max=0.99, step=0.01,\n",
    "                                value=0.83, description=\"Min ACC\"),\n",
    "    k_max=widgets.IntSlider(min=2, max=16*16, step=2, value=2**5, description=\"k_max\"),\n",
    "    mc_trials=widgets.IntSlider(min=300, max=500, step=10, value=100, description=\"MC Trials\"),\n",
    "    parallel_factor=widgets.IntSlider(min=1, max=256, step=1,\n",
    "                                      value=MODEL_CONFIGS['gpt5'].default_parallel,\n",
    "                                      description=\"Parallelism (P)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a31cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
